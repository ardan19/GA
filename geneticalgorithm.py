# -*- coding: utf-8 -*-
"""GeneticAlgorithm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GTYKLmUQRZfU0ZqcI3AgM_hBRLzAu1RH
"""

import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, mean_squared_error
from sklearn.decomposition import PCA

# Load dataset
iris = load_iris()
X = iris.data
y = iris.target

# PCA for dimensionality reduction
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

# Split dataset into training and testing sets
X_train_c2, X_test_c2, y_train_c2, y_test_c2 = train_test_split(X_pca, y, test_size=0.2, random_state=42)

# Function to calculate fitness (accuracy) of a solution
def calculate_fitness(solution):
    # Extract parameters from solution
    hidden_layer_sizes = (solution[0], solution[1], solution[2])
    activation = 'tanh'
    solver = 'adam'
    learning_rate_init = 0.001

    # Create and train MLPClassifier with given parameters
    mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, max_iter=50, activation=activation, solver=solver, learning_rate_init=learning_rate_init, random_state=1)
    mlp.fit(X_train_c2, y_train_c2)

    # Predict labels for test set
    predict_c2 = mlp.predict(X_test_c2)

    # Calculate accuracy
    accuracy = accuracy_score(y_test_c2, predict_c2)
    return accuracy

# Genetic Algorithm
population_size = 10
num_generations = 10
num_parameters = 3  # Number of parameters to be optimized: hidden_layer_sizes

# Generate initial population
population = np.random.randint(10, 200, size=(population_size, num_parameters))

for generation in range(num_generations):
    print(f"Generation {generation + 1}:")

    # Calculate fitness for each individual in population
    fitness_scores = [calculate_fitness(solution) for solution in population]

    # Select parents for crossover
    selected_indices = np.argsort(fitness_scores)[-2:]  # Select top 2 individuals as parents
    parents = population[selected_indices]

    # Perform crossover
    crossover_point = np.random.randint(1, num_parameters)  # Random crossover point
    offspring = np.concatenate((parents[0][:crossover_point], parents[1][crossover_point:]))

    # Perform mutation
    mutation_point = np.random.randint(num_parameters)  # Random mutation point
    mutation_value = np.random.randint(10, 200)  # Random mutation value
    offspring[mutation_point] = mutation_value

    # Replace worst individual with offspring
    worst_index = np.argmin(fitness_scores)
    population[worst_index] = offspring

    # Print best individual and its fitness score
    best_index = np.argmax(fitness_scores)
    print(f"Best individual: {population[best_index]}, Fitness: {fitness_scores[best_index]}")